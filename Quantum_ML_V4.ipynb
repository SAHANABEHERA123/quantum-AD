{"cells":[{"cell_type":"code","execution_count":1,"id":"6c086b96","metadata":{"id":"6c086b96","executionInfo":{"status":"ok","timestamp":1689552402856,"user_tz":240,"elapsed":4,"user":{"displayName":"Sahana B","userId":"07280146389403761083"}}},"outputs":[],"source":["# Vikram & Sahana\n","# Jan 28 2022\n","# Classical Machine Learning Model V4\n","# Detecting Severity of Alzheimer's with brain scans more accurately\n","\n","# Differences from V3\n","#   Quantum Enhanced"]},{"cell_type":"code","execution_count":2,"id":"434bfd09","metadata":{"id":"434bfd09","executionInfo":{"status":"error","timestamp":1689552405468,"user_tz":240,"elapsed":705,"user":{"displayName":"Sahana B","userId":"07280146389403761083"}},"outputId":"6e6530b2-a2f8-4cad-c1b4-dce8f25f04b2","colab":{"base_uri":"https://localhost:8080/","height":375}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-b09978e9a601>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pool_2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tflearn'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from tqdm import tqdm\n","import os\n","import cv2\n","import numpy as np\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from random import shuffle\n","import matplotlib.pyplot as plt\n","import tflearn\n","import nibabel as nib\n","from tflearn.layers.conv import conv_2d, max_pool_2d\n","from tflearn.layers.core import input_data, dropout, fully_connected\n","from tflearn.layers.estimator import regression\n","from tflearn.data_utils import to_categorical, image_preloader\n","from tflearn.metrics import Accuracy\n","import numpy as np\n","import pandas as pd\n","import skimage, os\n","from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n","from skimage.measure import label,regionprops, perimeter\n","from skimage.morphology import binary_dilation, binary_opening\n","from skimage.filters import roberts, sobel\n","from skimage import measure, feature\n","from skimage.segmentation import clear_border\n","from skimage import data\n","from scipy import ndimage as ndi\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n","import scipy.misc\n","import numpy as np\n","from glob import glob\n","from skimage.io import imread\n","import tensorflow as tf\n","tf.get_logger().setLevel('INFO')\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.preprocessing import MinMaxScaler\n","from time import time\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import concatenate\n","import numpy as np\n","import argparse\n","import locale\n","import os\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","import pennylane as qml\n","from pennylane import numpy as np\n","from pennylane.templates import RandomLayers\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n","from qiskit import execute, Aer, IBMQ\n","from qiskit.compiler import transpile\n","from time import perf_counter"]},{"cell_type":"code","execution_count":null,"id":"78dc1788","metadata":{"id":"78dc1788"},"outputs":[],"source":["def process_images(images_set, image_info):\n","    print()\n","    print(\"Processing Images...\")\n","    df = pd.read_csv(CSV_DIR) # reads in csv file\n","    df[\"Downloaded\"] = \"\" # creates new Downloaded column\n","\n","\n","    for index, row in df.iterrows(): # goes through every row\n","\n","        # CONNECTING EACH IMAGE TO ROW IN THE\n","        id = row['Image ID']\n","        for i in range(len(images_set)): # checks through all the images\n","            if \"I%s\" % id in image_info[i][0]:\n","                # if the image id is in the file name of the image being checked\n","                df.at[index,'Downloaded'] = i # store the index\n","                image_info[i][1] = True\n","\n","        if (row['Research Group'] in RG_CLASSIFICATIONS.keys()):\n","            df.at[index,'Research Group'] = RG_CLASSIFICATIONS[row['Research Group']]\n","        else:\n","            df.at[index,'Research Group'] = -1\n","        # CHANGING ANY COL,ROW WHERE IT SAYS NAN\n","        for col in df:\n","            if index > 0 and pd.isnull(row[col]):\n","                if row[\"Subject ID\"] == df.at[index-1,\"Subject ID\"]:\n","                    df.at[index, col] = df.at[index-1,col]\n","\n","        for colandval in INCLUDE_DATA_ROWS:\n","            coltoremove = colandval[0]\n","            valtoremove = colandval[1]\n","            if (valtoremove not in df.at[index, coltoremove]):\n","                df.at[index,'Research Group'] = -1\n","\n","    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n","    df.dropna(inplace=True)\n","\n","\n","    df2 = df.loc[df['Downloaded'] != \"\"]\n","    df3 = df2.loc[df2['Research Group'] != -1]\n","    print(\"Processed!\")\n","    return df3\n","\n","def process_lattributes(df, dat, verbose=True):\n","    print()\n","    if verbose: print(\"Processing Scan Attributes...\")\n","    cs = MinMaxScaler()\n","    continuous = cs.fit_transform(dat[INCLUDE_DATA_NUMBERS])\n","    categoricals = []\n","    for i in INCLUDE_DATA_CATEGORIES:\n","        zipBinarizer = LabelBinarizer().fit(df[i])\n","        categorical = zipBinarizer.transform(dat[i])\n","        categoricals.append(categorical)\n","\n","    x = np.hstack([continuous, *categoricals])\n","    if verbose: print(\"Processed!\")\n","    return x\n","\n","def get_data():\n","    print()\n","    print(\"Getting Images...\")\n","    path = IMAGE_DIR\n","    images = []\n","    image_info = []\n","    for fol1 in tqdm(os.listdir(path), disable=True):\n","        if fol1 == \".DS_Store\": continue\n","        path1 = os.path.join(path, fol1)\n","        for fol2 in tqdm(os.listdir(path1), disable=True):\n","            if fol2 == \".DS_Store\": continue\n","            path2 = os.path.join(path1, fol2)\n","            for fol3 in tqdm(os.listdir(path2), disable=True):\n","                if fol3 == \".DS_Store\": continue\n","                path3 = os.path.join(path2, fol3)\n","                for fol4 in tqdm(os.listdir(path3), disable=True):\n","                    if fol4 == \".DS_Store\": continue\n","                    path4 = os.path.join(path3, fol4)\n","                    # After going through all of the subfolders, we can finally see the image\n","                    for img in tqdm(os.listdir(path4), disable=True):\n","                        if img == \".DS_Store\": continue\n","                        # print(img)\n","                        try:\n","                            path5 = os.path.join(path4, img)\n","                            image_data = nib.load(path5).get_fdata() # get the numbers of the 3D image\n","                            image_data = np.rot90(image_data) # make it axial\n","                            \"\"\"\n","                            our_slice = image_data[image_data.shape[0]//2] # get the very middle slice\n","                            our_slice_reshaped = scale_array(our_slice, IMG_SHAPE)\n","                            images.append(our_slice_reshaped)\n","                            plt.imshow(our_slice_reshaped)\n","                            \"\"\"\n","\n","                            big_image = np.empty([IMG_SHAPE[0], IMG_SHAPE[1]*NUM_SLICES, 1])\n","                            for i in range(NUM_SLICES):\n","                                our_slice = image_data[image_data.shape[0]*(i+1)//(NUM_SLICES+1)]\n","                                our_slice_reshaped = scale_array(our_slice, IMG_SHAPE)\n","                                for r in range(IMG_SHAPE[0]):\n","                                    for c in range(IMG_SHAPE[1]):\n","                                        this_number = our_slice_reshaped[r,c,0]\n","                                        big_image[r,c+(IMG_SHAPE[1]*i),0] = this_number\n","\n","                            # print(big_image.shape)\n","                            # plt.imshow(big_image)\n","                            images.append(big_image) # add it to the list\n","\n","\n","                            image_info.append([img, False])\n","                        except:\n","                            pass\n","    print(\"Got!\")\n","    return images, image_info\n","\n","def get_classical_images(override = False, save = True):\n","    print()\n","    start = int(round(time()*1000))\n","    df_save_name = SAVE_PATH + \"/data_\" + DATA_SAVE_FILENAME + \".csv\"\n","    image_save_name = SAVE_PATH + \"/c_images_\" + DATA_SAVE_FILENAME + \".npy\"\n","    print(\"Getting Images and Data...\")\n","    try:\n","        c_images = np.load(image_save_name)\n","        df = pd.read_csv(df_save_name)\n","    except:\n","        override = True\n","\n","    if override:\n","        images_set, image_info = get_data()\n","        print(\"There are %s images\" % len(images_set))\n","        # view_image()\n","\n","\n","        df = process_images(images_set, image_info)\n","        print(\"DF's Shape: %s\" % str(df.shape))\n","\n","        print()\n","        print(\"Classical Images preprocessing...\")\n","        c_images = []\n","        for index in list(df[\"Downloaded\"]):\n","            c_images.append(images_set[index])\n","        c_images = np.array(c_images)\n","\n","        print(\"Saving images to %s\" % image_save_name)\n","        print(\"Saving dataframe to %s\" % df_save_name)\n","        if save: df.to_csv(df_save_name, index=False)\n","        if save: np.save(image_save_name, c_images)\n","        print(\"Preprocessed!\")\n","\n","    override = False\n","    c_images = np.load(image_save_name)\n","    df = pd.read_csv(df_save_name)\n","    end = int(round(time()*1000))\n","    pro_time = (end-start)/1000\n","    print()\n","    print(\"Got!\")\n","    print(\"That took %s minutes\" % (pro_time / 60))\n","    return df, c_images"]},{"cell_type":"code","execution_count":null,"id":"d46423fa","metadata":{"id":"d46423fa"},"outputs":[],"source":["def create_mlp(dim, regress=False, verbose=True):\n","    if (verbose): print(\"Creating MLP Classifier for attributes...\")\n","    # define our MLP network\n","    model = Sequential()\n","    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n","    model.add(Dense(4, activation=\"relu\"))\n","    # check to see if the regression node should be added\n","    if regress:\n","        model.add(Dense(1, activation=\"linear\"))\n","    # return our model\n","    if (verbose): print(\"Created!\")\n","    return model\n","\n","def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False, verbose=True):\n","    if (verbose): print(\"Creating CNN for images...\")\n","    # initialize the input shape and channel dimension, assuming\n","    # TensorFlow/channels-last ordering\n","    inputShape = (width, height, depth)\n","    chanDim = -1\n","    # define the model input\n","    inputs = Input(shape=inputShape)\n","    # loop over the number of filters\n","    for (i, f) in enumerate(filters):\n","        # if this is the first CONV layer then set the input\n","        # appropriately\n","        if i == 0:\n","            x = inputs\n","        # CONV => RELU => BN => POOL\n","        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n","        x = Activation(\"relu\")(x)\n","        x = BatchNormalization(axis=chanDim)(x)\n","        x = MaxPooling2D(pool_size=(2, 2))(x)\n","    # flatten the volume, then FC => RELU => BN => DROPOUT\n","    x = Flatten()(x)\n","    x = Dense(16)(x)\n","    x = Activation(\"relu\")(x)\n","    x = BatchNormalization(axis=chanDim)(x)\n","    x = Dropout(0.5)(x)\n","    # apply another FC layer, this one to match the number of nodes\n","    # coming out of the MLP\n","    x = Dense(4)(x)\n","    x = Activation(\"relu\")(x)\n","    # check to see if the regression node should be added\n","    if regress:\n","        x = Dense(1, activation=\"linear\")(x)\n","    # construct the CNN\n","    model = Model(inputs, x)\n","    # return the CNN\n","    if (verbose): print(\"Created!\")\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"164f2d9a","metadata":{"id":"164f2d9a"},"outputs":[],"source":["def scale_array(x, new_size):\n","    new_size = (new_size[0]/x.shape[0],new_size[1]/x.shape[1], 1)\n","    y = scipy.ndimage.zoom(x, new_size)\n","    return y\n","\n","def score(model, testNumX, testImagesX, testY, verbose=False):\n","    score = 0\n","    start = int(round(time()*1000))\n","    pred = model.predict([testNumX, testImagesX])\n","    end = int(round(time()*1000))\n","    for i in range(len(pred)):\n","        prediction = np.where(pred[i] == np.amax(pred[i]))[0][0]\n","        real = np.where(testY[i] == 1)[0][0]\n","        # print(pred[i], testY[i])\n","        if verbose: print(\"Predicted Class vs. Actual Class: %s %s\" % (prediction, real))\n","        if (prediction == real):\n","            score+=1\n","        else:\n","            if verbose: print(\"   Incorrect!\")\n","    return score / len(pred), end-start"]},{"cell_type":"code","execution_count":null,"id":"64853052","metadata":{"id":"64853052"},"outputs":[],"source":["dev = qml.device(\"default.qubit\", wires=4)\n","@qml.qnode(dev)\n","def circuit(phi):\n","\n","\n","    # Random circuit parameters\n","    rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n","    # Encoding of 4 classical input values\n","    for j in range(4):\n","        qml.RY(np.pi * phi[j], wires=j)\n","\n","    # Random quantum circuit\n","    RandomLayers(rand_params, wires=list(range(4)))\n","\n","    # Measurement producing 4 classical output values\n","    return [qml.expval(qml.PauliZ(j)) for j in range(4)]\n","\n","def quanv(image):\n","    \"\"\"Convolves the input image with many applications of the same quantum circuit.\"\"\"\n","    rr = IMG_SHAPE[0]\n","    cc = IMG_SHAPE[1]*NUM_SLICES\n","    out = np.zeros((rr//2, cc//2, 4))\n","\n","    # Loop over the coordinates of the top-left pixel of 2X2 squares\n","    for j in range(0, rr, 2):\n","        for k in range(0, cc, 2):\n","            # Process a squared 2x2 region of the image with a quantum circuit\n","            q_results = circuit(\n","                [\n","                    image[j, k, 0],\n","                    image[j, k + 1, 0],\n","                    image[j + 1, k, 0],\n","                    image[j + 1, k + 1, 0]\n","                ]\n","            )\n","            # Assign expectation values to different channels of the output pixel (j/2, k/2)\n","            for c in range(4):\n","                out[j // 2, k // 2, c] = q_results[c]\n","    return out\n","\n","def preprocess_quantum(images, override=False, save = True):\n","    start = int(round(time()*1000))\n","    print(\"Getting Quantum Images...\")\n","    image_save_path = SAVE_PATH + \"/q_images\" + DATA_SAVE_FILENAME + '.npy'\n","    try:\n","        np.load(image_save_path)\n","    except:\n","        override = True\n","    if override == True:\n","        q_images = []\n","        print(\"Preprocess images...\\n\")\n","        for idx, img in enumerate(images):\n","            print(\"{}/{}        \".format(idx + 1, len(images)), end=\"\\r\")\n","            q_images.append(quanv(img))\n","        q_images = np.asarray(q_images)\n","        print(\"Preprocessed!\")\n","\n","        # Save pre-processed images\n","\n","\n","        print(\"Saving to %s\" % image_save_path)\n","        if save: np.save(image_save_path, q_images)\n","\n","\n","    # Load pre-processed images\n","    override = False\n","    q_images = np.load(image_save_path)\n","    end = int(round(time()*1000))\n","    preprocess_time = (end-start)/1000\n","    print(\"\\nGot!\")\n","    print(\"That took %s mins - (%s sec)\" % (round(preprocess_time/60, 2), round(preprocess_time, 2)))\n","    return q_images"]},{"cell_type":"code","execution_count":null,"id":"4305ad52","metadata":{"id":"4305ad52"},"outputs":[],"source":["# OPTIONAL\n","\n","def view_image():\n","    import numpy as np # linear algebra\n","    import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","    import skimage, os\n","    from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n","    from skimage.measure import label,regionprops, perimeter\n","    from skimage.morphology import binary_dilation, binary_opening\n","    from skimage.filters import roberts, sobel\n","    from skimage import measure, feature\n","    from skimage.segmentation import clear_border\n","    from skimage import data\n","    from scipy import ndimage as ndi\n","    import matplotlib.pyplot as plt\n","    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n","    import scipy.misc\n","    import numpy as np\n","    from glob import glob\n","    from skimage.io import imread\n","    BASE_IMG_PATH = \"/Users/sidharthanantha/Documents/SciFair 2022/ADNI/002_S_6030/Axial_T2_STAR/2017-06-15_13_30_22.0/S573170/ADNI_002_S_6030_MR_Axial_T2_STAR__br_raw_20170616113815278_41_S573170_I861966.nii\"\n","\n","    image = glob(os.path.join(BASE_IMG_PATH, '*'))\n","    image = glob(BASE_IMG_PATH)[0]\n","    print(image)\n","    %matplotlib inline\n","    try:\n","        import nibabel as nib\n","    except:\n","        raise ImportError('bip bop')\n","\n","    image_data = nib.load(image).get_data()\n","    image_data = np.rot90(image_data)\n","    # image_data = np.reshape(image_data, (44, 256, 256, 1))\n","    # image_data = np.rot90(image_data) # make it axial\n","    # print(image_data.shape)\n","    le_img = image_data[image_data.shape[0]//2]\n","    plt.imshow(le_img)\n","    # print(le_img[len(le_img)//2])\n","    # print(le_img.shape)\n","    le_img = scale_array(le_img, (70,70))\n","    plt.imshow(le_img)\n","    # print(image_data[2])\n","\n","\n","def show_q_images(c_images, q_images):\n","    n_samples = 4\n","    n_channels = 4\n","    fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n","    for k in range(n_samples):\n","        axes[0, 0].set_ylabel(\"Input\")\n","        if k != 0:\n","            axes[0, k].yaxis.set_visible(False)\n","        axes[0, k].imshow(c_images[k, :, :, 0], cmap=\"gray\")\n","\n","        # Plot all output channels\n","        for c in range(n_channels):\n","            axes[c + 1, 0].set_ylabel(\"Output [ch. {}]\".format(c))\n","            if k != 0:\n","                axes[c, k].yaxis.set_visible(False)\n","            axes[c + 1, k].imshow(q_images[k, :, :, c], cmap=\"gray\")\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"bc75b7ab","metadata":{"id":"bc75b7ab"},"outputs":[],"source":["n_layers = 1\n","\n","EPOCHS = 200\n","LR = 1e-3\n","\n","np.random.seed(0)\n","tf.random.set_seed(0)"]},{"cell_type":"code","execution_count":null,"id":"ffd3c38a","metadata":{"id":"ffd3c38a"},"outputs":[],"source":["VERSION = 'V4_FINAL' # used for saving model name\n","DATA_VERSION = 'V3' # used for retrieving imgs + csv, and saving imgs + df\n","\n","SAVE_PATH = \"/Users/sidharthanantha/Documents/SciFair 2022/SaveData\" # path for saving imgs, models, df\n","IMAGE_DIR = \"/Users/sidharthanantha/Documents/SciFair 2022/Alzheimers_Dataset_%s\" % (DATA_VERSION)\n","CSV_DIR = \"/Users/sidharthanantha/Documents/SciFair 2022/classical_v2_attr_data.csv\"\n","\n","IMG_SHAPE = (70, 70)\n","MODEL_NAME = \"classifying_alzheimers_%s.model\" % VERSION # saves ml model under this name\n","Y_ATTR = \"Research Group\"\n","\n","INCLUDE_DATA_NUMBERS = ['Weight','APOE A1','APOE A2','Age','MMSE Total Score','GDSCALE Total Score','Global CDR','FAQ Total Score','NPI-Q Total Score']\n","INCLUDE_DATA_CATEGORIES = ['Sex', 'Description','Type','Imaging Protocol','Structure']\n","INCLUDE_DATA_ROWS = [\n","    ['Imaging Protocol', 'Field Strength=3.0'],\n","#     ['Imaging Protocol', 'Acquisition Type=2D'],\n","#     ['Imaging Protocol', 'Weighting=PD'],\n","]\n","\n","RG_CLASSIFICATIONS = {\n","    \"CN\": 0,\n","    \"AD\": 1,\n","    \"MCI\": 2,\n","    \"EMCI\": 2,\n","    \"LMCI\": 2,\n","    \"SMC\": 2,\n","}\n","NUM_SLICES = 1 # how many brain slices\n","NUM_TIMES_TEST = 5 # how many times should the alg be tested\n","NUM_CLASSES = len(list(set(RG_CLASSIFICATIONS.values())))\n","\n","DATA_SAVE_FILENAME = \"%s_%sslices_%sclasses_%smodel\" % (DATA_VERSION, NUM_SLICES, NUM_CLASSES, VERSION) # to save dfs and imgs"]},{"cell_type":"code","execution_count":null,"id":"ef22066c","metadata":{"id":"ef22066c","outputId":"fbc4b038-ae4c-4a37-825b-d61608b43bde"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Getting Images and Data...\n","\n","Getting Images...\n","Got!\n","There are 11855 images\n","\n","Processing Images...\n","Processed!\n","DF's Shape: (1537, 22)\n","\n","Classical Images preprocessing...\n","Saving images to /Users/sidharthanantha/Documents/SciFair 2022/SaveData/c_images_V3_1slices_3classes_V4_FINALmodel.npy\n","Saving dataframe to /Users/sidharthanantha/Documents/SciFair 2022/SaveData/data_V3_1slices_3classes_V4_FINALmodel.csv\n","Preprocessed!\n","\n","Got!\n","That took 13.079716666666666 minutes\n","Shape of the Image array: (1537, 70, 70, 1)\n","\n"]}],"source":["df, c_images = get_classical_images()\n","print(\"Shape of the Image array: %s\\n\" % str(np.shape(c_images)))"]},{"cell_type":"code","execution_count":null,"id":"f6efb433","metadata":{"id":"f6efb433","outputId":"3ee90b6c-93d3-4d3e-a926-f3b98189fb11"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject ID</th>\n","      <th>Sex</th>\n","      <th>Weight</th>\n","      <th>Research Group</th>\n","      <th>APOE A1</th>\n","      <th>APOE A2</th>\n","      <th>Visit</th>\n","      <th>Study Date</th>\n","      <th>Age</th>\n","      <th>Global CDR</th>\n","      <th>...</th>\n","      <th>GDSCALE Total Score</th>\n","      <th>FAQ Total Score</th>\n","      <th>Modality</th>\n","      <th>Description</th>\n","      <th>Type</th>\n","      <th>Imaging Protocol</th>\n","      <th>Image ID</th>\n","      <th>Structure</th>\n","      <th>Registration</th>\n","      <th>Downloaded</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>002_S_0413</td>\n","      <td>F</td>\n","      <td>60.4</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>ADNI Baseline</td>\n","      <td>5/19/2006</td>\n","      <td>76.4</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>MRI</td>\n","      <td>Double_TSE</td>\n","      <td>Original</td>\n","      <td>Slice Thickness=3.0;Matrix Z=52.0;Manufacturer...</td>\n","      <td>15804</td>\n","      <td>Brain</td>\n","      <td>native</td>\n","      <td>10459</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>002_S_0413</td>\n","      <td>F</td>\n","      <td>60.8</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>ADNI1/GO Month 6</td>\n","      <td>11/15/2006</td>\n","      <td>76.9</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>MRI</td>\n","      <td>SURVEY</td>\n","      <td>Original</td>\n","      <td>Slice Thickness=10.0;Matrix Z=3.0;Manufacturer...</td>\n","      <td>30120</td>\n","      <td>Brain</td>\n","      <td>native</td>\n","      <td>8601</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>002_S_0413</td>\n","      <td>F</td>\n","      <td>60.1</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>ADNI1/GO Month 12</td>\n","      <td>6/01/2007</td>\n","      <td>77.5</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>MRI</td>\n","      <td>Double_TSE</td>\n","      <td>Original</td>\n","      <td>Slice Thickness=3.0;Matrix Z=48.0;Manufacturer...</td>\n","      <td>55787</td>\n","      <td>Brain</td>\n","      <td>native</td>\n","      <td>3684</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>002_S_0413</td>\n","      <td>F</td>\n","      <td>60.1</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>ADNI1/GO Month 12</td>\n","      <td>6/01/2007</td>\n","      <td>77.5</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>MRI</td>\n","      <td>SURVEY</td>\n","      <td>Original</td>\n","      <td>Slice Thickness=10.0;Matrix Z=3.0;Manufacturer...</td>\n","      <td>55784</td>\n","      <td>Brain</td>\n","      <td>native</td>\n","      <td>3681</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>002_S_0413</td>\n","      <td>F</td>\n","      <td>57.7</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>ADNI1/GO Month 24</td>\n","      <td>7/31/2008</td>\n","      <td>78.6</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>MRI</td>\n","      <td>Double_TSE</td>\n","      <td>Original</td>\n","      <td>Slice Thickness=3.0;Matrix Z=51.0;Manufacturer...</td>\n","      <td>115004</td>\n","      <td>Brain</td>\n","      <td>native</td>\n","      <td>3683</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1532</th>\n","      <td>941_S_4377</td>\n","      <td>F</td>\n","      <td>123.4</td>\n","      <td>2</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>ADNI2 Month 6-New Pt</td>\n","      <td>8/16/2012</td>\n","      <td>70.1</td>\n","      <td>0.5</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>MRI</td>\n","      <td>localizer</td>\n","      <td>Original</td>\n","      <td>Slice Thickness=8.0;Matrix Z=1.0;Acquisition T...</td>\n","      <td>324374</td>\n","      <td>Brain</td>\n","      <td>native</td>\n","      <td>10328</td>\n","    </tr>\n","    <tr>\n","      <th>1533</th>\n","      <td>941_S_4377</td>\n","      <td>F</td>\n","      <td>123.4</td>\n","      <td>2</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>ADNI2 Month 6-New Pt</td>\n","      <td>8/16/2012</td>\n","      <td>70.1</td>\n","      <td>0.5</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>MRI</td>\n","      <td>localizer</td>\n","      <td>Original</td>\n","      <td>Slice Thickness=8.0;Matrix Z=1.0;Acquisition T...</td>\n","      <td>324372</td>\n","      <td>Brain</td>\n","      <td>native</td>\n","      <td>10329</td>\n","    </tr>\n","    <tr>\n","      <th>1534</th>\n","      <td>941_S_4377</td>\n","      <td>F</td>\n","      <td>123.4</td>\n","      <td>2</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>ADNI2 Month 6-New Pt</td>\n","      <td>8/16/2012</td>\n","      <td>70.1</td>\n","      <td>0.5</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>MRI</td>\n","      <td>AXIAL_T2_STAR</td>\n","      <td>Original</td>\n","      <td>Slice Thickness=4.0;Matrix Z=44.0;Acquisition ...</td>\n","      <td>324377</td>\n","      <td>Brain</td>\n","      <td>native</td>\n","      <td>10327</td>\n","    </tr>\n","    <tr>\n","      <th>1535</th>\n","      <td>941_S_4420</td>\n","      <td>M</td>\n","      <td>75.3</td>\n","      <td>2</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>ADNI2 Month 6-New Pt</td>\n","      <td>12/21/2012</td>\n","      <td>82.2</td>\n","      <td>0.5</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>MRI</td>\n","      <td>ADNI_gre_field_mapping</td>\n","      <td>Original</td>\n","      <td>Slice Thickness=3.0;Matrix Z=45.0;Acquisition ...</td>\n","      <td>352803</td>\n","      <td>Brain</td>\n","      <td>native</td>\n","      <td>363</td>\n","    </tr>\n","    <tr>\n","      <th>1536</th>\n","      <td>941_S_4420</td>\n","      <td>M</td>\n","      <td>75.3</td>\n","      <td>2</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>ADNI2 Month 6-New Pt</td>\n","      <td>12/21/2012</td>\n","      <td>82.2</td>\n","      <td>0.5</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>MRI</td>\n","      <td>ADNI_gre_field_mapping</td>\n","      <td>Original</td>\n","      <td>Slice Thickness=3.0;Matrix Z=45.0;Acquisition ...</td>\n","      <td>352820</td>\n","      <td>Brain</td>\n","      <td>native</td>\n","      <td>362</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1537 rows Ã— 22 columns</p>\n","</div>"],"text/plain":["      Subject ID Sex  Weight  Research Group  APOE A1  APOE A2  \\\n","0     002_S_0413   F    60.4               0      3.0      3.0   \n","1     002_S_0413   F    60.8               0      3.0      3.0   \n","2     002_S_0413   F    60.1               0      3.0      3.0   \n","3     002_S_0413   F    60.1               0      3.0      3.0   \n","4     002_S_0413   F    57.7               0      3.0      3.0   \n","...          ...  ..     ...             ...      ...      ...   \n","1532  941_S_4377   F   123.4               2      3.0      4.0   \n","1533  941_S_4377   F   123.4               2      3.0      4.0   \n","1534  941_S_4377   F   123.4               2      3.0      4.0   \n","1535  941_S_4420   M    75.3               2      3.0      3.0   \n","1536  941_S_4420   M    75.3               2      3.0      3.0   \n","\n","                     Visit  Study Date   Age  Global CDR  ...  \\\n","0            ADNI Baseline   5/19/2006  76.4         0.0  ...   \n","1         ADNI1/GO Month 6  11/15/2006  76.9         0.0  ...   \n","2        ADNI1/GO Month 12   6/01/2007  77.5         0.0  ...   \n","3        ADNI1/GO Month 12   6/01/2007  77.5         0.0  ...   \n","4        ADNI1/GO Month 24   7/31/2008  78.6         0.0  ...   \n","...                    ...         ...   ...         ...  ...   \n","1532  ADNI2 Month 6-New Pt   8/16/2012  70.1         0.5  ...   \n","1533  ADNI2 Month 6-New Pt   8/16/2012  70.1         0.5  ...   \n","1534  ADNI2 Month 6-New Pt   8/16/2012  70.1         0.5  ...   \n","1535  ADNI2 Month 6-New Pt  12/21/2012  82.2         0.5  ...   \n","1536  ADNI2 Month 6-New Pt  12/21/2012  82.2         0.5  ...   \n","\n","      GDSCALE Total Score  FAQ Total Score  Modality             Description  \\\n","0                     0.0              0.0       MRI              Double_TSE   \n","1                     0.0              0.0       MRI                  SURVEY   \n","2                     1.0              0.0       MRI              Double_TSE   \n","3                     1.0              0.0       MRI                  SURVEY   \n","4                     0.0              0.0       MRI              Double_TSE   \n","...                   ...              ...       ...                     ...   \n","1532                  2.0              2.0       MRI               localizer   \n","1533                  2.0              2.0       MRI               localizer   \n","1534                  2.0              2.0       MRI           AXIAL_T2_STAR   \n","1535                  4.0              1.0       MRI  ADNI_gre_field_mapping   \n","1536                  4.0              1.0       MRI  ADNI_gre_field_mapping   \n","\n","          Type                                   Imaging Protocol Image ID  \\\n","0     Original  Slice Thickness=3.0;Matrix Z=52.0;Manufacturer...    15804   \n","1     Original  Slice Thickness=10.0;Matrix Z=3.0;Manufacturer...    30120   \n","2     Original  Slice Thickness=3.0;Matrix Z=48.0;Manufacturer...    55787   \n","3     Original  Slice Thickness=10.0;Matrix Z=3.0;Manufacturer...    55784   \n","4     Original  Slice Thickness=3.0;Matrix Z=51.0;Manufacturer...   115004   \n","...        ...                                                ...      ...   \n","1532  Original  Slice Thickness=8.0;Matrix Z=1.0;Acquisition T...   324374   \n","1533  Original  Slice Thickness=8.0;Matrix Z=1.0;Acquisition T...   324372   \n","1534  Original  Slice Thickness=4.0;Matrix Z=44.0;Acquisition ...   324377   \n","1535  Original  Slice Thickness=3.0;Matrix Z=45.0;Acquisition ...   352803   \n","1536  Original  Slice Thickness=3.0;Matrix Z=45.0;Acquisition ...   352820   \n","\n","     Structure  Registration Downloaded  \n","0        Brain        native      10459  \n","1        Brain        native       8601  \n","2        Brain        native       3684  \n","3        Brain        native       3681  \n","4        Brain        native       3683  \n","...        ...           ...        ...  \n","1532     Brain        native      10328  \n","1533     Brain        native      10329  \n","1534     Brain        native      10327  \n","1535     Brain        native        363  \n","1536     Brain        native        362  \n","\n","[1537 rows x 22 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":null,"id":"d7069c65","metadata":{"id":"d7069c65","outputId":"56343e75-f59e-4e69-94b1-d53d5b4f39ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Getting Quantum Images...\n","Preprocess images...\n","\n","Preprocessed!    \n","Saving to /Users/sidharthanantha/Documents/SciFair 2022/SaveData/q_imagesV3_1slices_3classes_V4_FINALmodel.npy\n","\n","Got!\n","That took 313.42 mins - (18805.5 sec)\n"]}],"source":["q_images = preprocess_quantum(c_images)\n","# show_q_images(c_images, q_images)"]},{"cell_type":"code","execution_count":null,"id":"0f1fff40","metadata":{"id":"0f1fff40"},"outputs":[],"source":["def splite(split, verbose=True):\n","    (trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n","\n","    trainY = to_categorical(np.array(trainAttrX[Y_ATTR]))\n","    testY = to_categorical(np.array(testAttrX[Y_ATTR]))\n","    trainAttrX\n","\n","    trainNumX = process_lattributes(df, trainAttrX, verbose=verbose)\n","    testNumX = process_lattributes(df, testAttrX, verbose=verbose)\n","\n","    return trainNumX, testNumX, trainImagesX, testImagesX, trainY, testY\n","\n","def make(trainNumX, testNumX, trainImagesX, testImagesX, trainY, testY, verbose=True):\n","    mlp = create_mlp(trainNumX.shape[1], regress=False, verbose=verbose)\n","    cnn = create_cnn(*np.shape(trainImagesX[0]), regress=False, verbose=verbose)\n","    combinedInput = concatenate([mlp.output, cnn.output])\n","\n","    x = Dense(4, activation=\"relu\")(combinedInput)\n","    x = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n","    model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n","    opt = Adam(learning_rate=1e-3, decay=1e-3 / 200)\n","    model.compile(loss=\"categorical_crossentropy\", optimizer=opt)\n","    return model\n","\n","def traine(trainNumX, testNumX, trainImagesX, testImagesX, trainY, testY, model, verbose=True):\n","    if (verbose): print(\"Fitting...\")\n","    start = int(round(time()*1000))\n","    model.fit(\n","        x=[trainNumX, trainImagesX], y=trainY,\n","        epochs=EPOCHS, batch_size=8, verbose=False)\n","    end = int(round(time()*1000))\n","    train_time = (end-start)/1000\n","    if (verbose): print(\"Fitted!\")\n","    return model, train_time\n","\n","def teste(trainNumX, testNumX, trainImagesX, testImagesX, trainY, testY, train_time, model):\n","    lescore, pred_time = score(model, testNumX, testImagesX, testY, verbose=False)\n","\n","    print(\"After training the model with %s inputs and %s tests, here are the results\"%(trainY.shape[0], testY.shape[0]))\n","    print(\"-----------\")\n","    print(\"Time to train (%s inputs, epoch=%s): %s mins - (%s sec)\" % (trainY.shape[0], EPOCHS, round(train_time/60, 2), round(train_time, 2)))\n","    print(\"Time to predict (%s values) in ms: %s\" % (testY.shape[0], pred_time))\n","    print(\"Score: %s%%\" % (lescore*100))\n","    print(\"-----------\")\n","\n","    model.save(SAVE_PATH + \"/\" + MODEL_NAME)\n","    return lescore*100\n","\n","def do(split, which):\n","    print(\"--------%s--------\" % which)\n","    total_scores = 0\n","    total_time = 0\n","    for i in range(NUM_TIMES_TEST):\n","        print()\n","        all_the_data = splite(split, verbose=False)\n","        model = make(*all_the_data, verbose=False)\n","        model, train_time = traine(*all_the_data, model)\n","        the_score = teste(*all_the_data, train_time, model)\n","        total_scores += the_score\n","        total_time += train_time\n","    print(\"\\n\")\n","    return (total_scores/NUM_TIMES_TEST), (total_time/NUM_TIMES_TEST)"]},{"cell_type":"code","execution_count":null,"id":"1a66ec98","metadata":{"id":"1a66ec98","outputId":"7ad0421e-211d-43b0-c606-ff5de23dfacc"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------Quantum--------\n","\n","\n","\n","WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"]},{"name":"stdout","output_type":"stream","text":["Fitting...\n"]},{"name":"stderr","output_type":"stream","text":["2022-02-11 07:24:46.279711: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Fitted!\n","After training the model with 1152 inputs and 385 tests, here are the results\n","-----------\n","Time to train (1152 inputs, epoch=200): 8.16 mins - (489.71 sec)\n","Time to predict (385 values) in ms: 347\n","Score: 81.03896103896105%\n","-----------\n","\n","\n","\n","Fitting...\n","Fitted!\n","After training the model with 1152 inputs and 385 tests, here are the results\n","-----------\n","Time to train (1152 inputs, epoch=200): 8.91 mins - (534.84 sec)\n","Time to predict (385 values) in ms: 403\n","Score: 81.2987012987013%\n","-----------\n","\n","\n","\n","Fitting...\n","Fitted!\n","After training the model with 1152 inputs and 385 tests, here are the results\n","-----------\n","Time to train (1152 inputs, epoch=200): 8.43 mins - (505.77 sec)\n","Time to predict (385 values) in ms: 356\n","Score: 81.81818181818183%\n","-----------\n","\n","\n","\n","Fitting...\n","Fitted!\n","After training the model with 1152 inputs and 385 tests, here are the results\n","-----------\n","Time to train (1152 inputs, epoch=200): 9.37 mins - (562.09 sec)\n","Time to predict (385 values) in ms: 547\n","Score: 82.07792207792208%\n","-----------\n","\n","\n","\n","Fitting...\n","Fitted!\n","After training the model with 1152 inputs and 385 tests, here are the results\n","-----------\n","Time to train (1152 inputs, epoch=200): 8.73 mins - (523.98 sec)\n","Time to predict (385 values) in ms: 592\n","Score: 82.33766233766234%\n","-----------\n","\n","\n","\n","Quantum----------\n","Avg Scores:     81.71429%\n","Avg Train Time: 8.72 mins - (523.28 sec)\n","\n","\n","///////////////\n","Using DataVersion V3, Model V4_FINAL, Img Shape (70, 70), 1 slice(s), 3 classifications:\n","\n","Quantum----------\n","Avg Scores:     81.71429%\n","Avg Train Time: 8.72 mins - (523.28 sec)\n"]}],"source":["split_q = train_test_split(df, q_images, test_size=0.25, random_state=42)\n","split_c = train_test_split(df, c_images, test_size=0.25, random_state=42)\n","splits = [\n","    [split_q, \"Quantum\"],\n","#     [split_c, \"Classical\"]\n","]\n","avgs = []\n","for er in splits:\n","    avg = do(*er)\n","    avgs.append(avg)\n","    for avg in avgs:\n","        print()\n","        print(\"%s----------\" % splits[avgs.index(avg)][1])\n","\n","    print(\"Avg Scores:     %s%%\" % round(avg[0], 5))\n","    print(\"Avg Train Time: %s mins - (%s sec)\" % (round(avg[1]/60, 2), round(avg[1], 2)))\n","print(\"\\n\\n///////////////\")\n","print(\"Using DataVersion %s, Model %s, Img Shape %s, %s slice(s), %s classifications:\"\n","      % (DATA_VERSION, VERSION, IMG_SHAPE, NUM_SLICES, NUM_CLASSES))\n","for avg in avgs:\n","    print()\n","    print(\"%s----------\" % splits[avgs.index(avg)][1])\n","\n","    print(\"Avg Scores:     %s%%\" % round(avg[0], 5))\n","    print(\"Avg Train Time: %s mins - (%s sec)\" % (round(avg[1]/60, 2), round(avg[1], 2)))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}
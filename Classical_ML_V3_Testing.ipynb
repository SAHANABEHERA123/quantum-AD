{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c086b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vikram & Sahana\n",
    "# Jan 28 2022\n",
    "# Classical Machine Learning Model V3 - TESTING\n",
    "# Detecting Severity of Alzheimer's with brain scans more accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "434bfd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tflearn\n",
    "import nibabel as nib\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_utils import to_categorical, image_preloader\n",
    "from tflearn.metrics import Accuracy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage, os\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('INFO')\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit import execute, Aer, IBMQ\n",
    "from qiskit.compiler import transpile\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78dc1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(images_set, image_info):\n",
    "    print()\n",
    "    print(\"Processing Images...\")\n",
    "    df = pd.read_csv(CSV_DIR) # reads in csv file\n",
    "    df[\"Downloaded\"] = \"\" # creates new Downloaded column\n",
    "    \n",
    "    \n",
    "    for index, row in df.iterrows(): # goes through every row\n",
    "        \n",
    "        # CONNECTING EACH IMAGE TO ROW IN THE \n",
    "        id = row['Image ID']\n",
    "        for i in range(len(images_set)): # checks through all the images\n",
    "            if \"I%s\" % id in image_info[i][0]:\n",
    "                # if the image id is in the file name of the image being checked\n",
    "                df.at[index,'Downloaded'] = i # store the index\n",
    "                image_info[i][1] = True\n",
    "            \n",
    "        if (row['Research Group'] in RG_CLASSIFICATIONS.keys()): \n",
    "            df.at[index,'Research Group'] = RG_CLASSIFICATIONS[row['Research Group']]\n",
    "        else:\n",
    "            df.at[index,'Research Group'] = -1\n",
    "        # CHANGING ANY COL,ROW WHERE IT SAYS NAN\n",
    "        for col in df:\n",
    "            if index > 0 and pd.isnull(row[col]):\n",
    "                if row[\"Subject ID\"] == df.at[index-1,\"Subject ID\"]:\n",
    "                    df.at[index, col] = df.at[index-1,col]\n",
    "                    \n",
    "        for colandval in INCLUDE_DATA_ROWS:\n",
    "            coltoremove = colandval[0]\n",
    "            valtoremove = colandval[1]\n",
    "            if (valtoremove not in df.at[index, coltoremove]):\n",
    "                df.at[index,'Research Group'] = -1\n",
    "                \n",
    "        \n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)   \n",
    "    df.dropna(inplace=True) \n",
    "    \n",
    "    \n",
    "    df2 = df.loc[df['Downloaded'] != \"\"]\n",
    "    df3 = df2.loc[df2['Research Group'] != -1]\n",
    "    print(\"Processed!\")\n",
    "    return df3\n",
    "\n",
    "def test_process_lattributes(df, dat):\n",
    "    all_data = []\n",
    "    all_data_info = []\n",
    "    for test_this in TEST_COLS:\n",
    "        try_these_points = [[], []]\n",
    "        for asdf in INCLUDE_DATA_NUMBERS:\n",
    "            if test_this != asdf: try_these_points[0].append(asdf)\n",
    "        for asdf in INCLUDE_DATA_CATEGORIES:\n",
    "            if test_this != asdf: try_these_points[1].append(asdf)\n",
    "        le_data = actual_process_lattributes(df, dat, cols=try_these_points)\n",
    "        all_data.append(le_data)\n",
    "        all_data_info.append(\"Remove Col: %s\" % test_this)\n",
    "        \n",
    "    for colandval in INCLUDE_DATA_ROWS:\n",
    "        coltoremove = colandval[0]\n",
    "        valtoremove = colandval[1]\n",
    "        if (coltoremove in list(df)): df_test = df.loc[df[coltoremove].str.contains(valtoremove)]\n",
    "        else: df_test = df.loc[df[\"Downloaded\"] != \"Boogie Woogie\"]\n",
    "        try_these_points = [[], []]\n",
    "        for asdf in INCLUDE_DATA_NUMBERS:\n",
    "            if coltoremove != asdf: try_these_points[0].append(asdf)\n",
    "        for asdf in INCLUDE_DATA_CATEGORIES:\n",
    "            if coltoremove != asdf: try_these_points[1].append(asdf)\n",
    "        if (df_test.shape[0] == 0):\n",
    "            print(\"Specifying %s down to %s doesn't work... Make sure you downloaded / are checking the right thing\"\n",
    "                 % (coltoremove, valtoremove))\n",
    "            continue\n",
    "        le_data = actual_process_lattributes(df_test, dat, cols=try_these_points)\n",
    "        all_data.append(le_data)\n",
    "        all_data_info.append(\"Filter from %s: %s\" % (coltoremove, valtoremove))\n",
    "        \n",
    "    return all_data, all_data_info\n",
    "\n",
    "def actual_process_lattributes(df, dat, cols=[INCLUDE_DATA_NUMBERS, INCLUDE_DATA_CATEGORIES]):\n",
    "\n",
    "    print(\"Processing Scan Attributes...\")\n",
    "    cs = MinMaxScaler()\n",
    "    \n",
    "    continuous = cs.fit_transform(dat[cols[0]])\n",
    "    categoricals = []\n",
    "    for i in cols[1]:\n",
    "        zipBinarizer = LabelBinarizer().fit(df[i])\n",
    "        categorical = zipBinarizer.transform(dat[i])\n",
    "        categoricals.append(categorical)\n",
    "    \n",
    "    x = np.hstack([continuous, *categoricals])\n",
    "    print(\"Processed!\")\n",
    "    return x\n",
    "\n",
    "def process_lattributes(df, dat, verbose=True):\n",
    "    print()\n",
    "    if verbose: print(\"Processing Scan Attributes...\")\n",
    "    cs = MinMaxScaler()\n",
    "    continuous = cs.fit_transform(dat[INCLUDE_DATA_NUMBERS])\n",
    "    categoricals = []\n",
    "    for i in INCLUDE_DATA_CATEGORIES:\n",
    "        zipBinarizer = LabelBinarizer().fit(df[i])\n",
    "        categorical = zipBinarizer.transform(dat[i])\n",
    "        categoricals.append(categorical)\n",
    "    \n",
    "    x = np.hstack([continuous, *categoricals])\n",
    "    if verbose: print(\"Processed!\")\n",
    "    return x\n",
    "\n",
    "def get_data():\n",
    "    print()\n",
    "    print(\"Getting Images...\")\n",
    "    path = IMAGE_DIR\n",
    "    images = []\n",
    "    image_info = []\n",
    "    for fol1 in tqdm(os.listdir(path), disable=True):\n",
    "        if fol1 == \".DS_Store\": continue\n",
    "        path1 = os.path.join(path, fol1)\n",
    "        for fol2 in tqdm(os.listdir(path1), disable=True):\n",
    "            if fol2 == \".DS_Store\": continue\n",
    "            path2 = os.path.join(path1, fol2)\n",
    "            for fol3 in tqdm(os.listdir(path2), disable=True):\n",
    "                if fol3 == \".DS_Store\": continue\n",
    "                path3 = os.path.join(path2, fol3)\n",
    "                for fol4 in tqdm(os.listdir(path3), disable=True):\n",
    "                    if fol4 == \".DS_Store\": continue\n",
    "                    path4 = os.path.join(path3, fol4)\n",
    "                    # After going through all of the subfolders, we can finally see the image\n",
    "                    for img in tqdm(os.listdir(path4), disable=True):\n",
    "                        if img == \".DS_Store\": continue\n",
    "                        # print(img)\n",
    "                        try:\n",
    "                            path5 = os.path.join(path4, img)\n",
    "                            image_data = nib.load(path5).get_fdata() # get the numbers of the 3D image\n",
    "                            image_data = np.rot90(image_data) # make it axial\n",
    "                            \"\"\"\n",
    "                            our_slice = image_data[image_data.shape[0]//2] # get the very middle slice\n",
    "                            our_slice_reshaped = scale_array(our_slice, IMG_SHAPE)\n",
    "                            images.append(our_slice_reshaped)\n",
    "                            plt.imshow(our_slice_reshaped)\n",
    "                            \"\"\"\n",
    "\n",
    "                            big_image = np.empty([IMG_SHAPE[0], IMG_SHAPE[1]*NUM_SLICES, 1])\n",
    "                            for i in range(NUM_SLICES):\n",
    "                                our_slice = image_data[image_data.shape[0]*(i+1)//(NUM_SLICES+1)]\n",
    "                                our_slice_reshaped = scale_array(our_slice, IMG_SHAPE)\n",
    "                                for r in range(IMG_SHAPE[0]): \n",
    "                                    for c in range(IMG_SHAPE[1]): \n",
    "                                        this_number = our_slice_reshaped[r,c,0]\n",
    "                                        big_image[r,c+(IMG_SHAPE[1]*i),0] = this_number\n",
    "\n",
    "                            # print(big_image.shape)\n",
    "                            # plt.imshow(big_image)\n",
    "                            images.append(big_image) # add it to the list\n",
    "\n",
    "\n",
    "                            image_info.append([img, False])\n",
    "                        except:\n",
    "                            pass\n",
    "    print(\"Got!\")\n",
    "    return images, image_info\n",
    "\n",
    "def get_classical_images(override = False, save = True):\n",
    "    print()\n",
    "    start = int(round(time()*1000))\n",
    "    df_save_name = SAVE_PATH + \"/data_\" + DATA_SAVE_FILENAME + \".csv\"\n",
    "    image_save_name = SAVE_PATH + \"/c_images_\" + DATA_SAVE_FILENAME + \".npy\"\n",
    "    print(\"Getting Images and Data...\")\n",
    "    try:\n",
    "        c_images = np.load(image_save_name)\n",
    "        df = pd.read_csv(df_save_name)\n",
    "    except:\n",
    "        override = True\n",
    "        \n",
    "    if override:\n",
    "        images_set, image_info = get_data()\n",
    "        print(\"There are %s images\" % len(images_set))\n",
    "        # view_image()\n",
    "        \n",
    "\n",
    "        df = process_images(images_set, image_info)\n",
    "        print(\"DF's Shape: %s\" % str(df.shape))\n",
    "\n",
    "        print()\n",
    "        print(\"Classical Images preprocessing...\")\n",
    "        c_images = []\n",
    "        for index in list(df[\"Downloaded\"]):\n",
    "            c_images.append(images_set[index])\n",
    "        c_images = np.array(c_images)\n",
    "        \n",
    "        print(\"Saving images to %s\" % image_save_name)\n",
    "        print(\"Saving dataframe to %s\" % df_save_name)\n",
    "        if save: df.to_csv(df_save_name, index=False)\n",
    "        if save: np.save(image_save_name, c_images)\n",
    "        print(\"Preprocessed!\")\n",
    "        \n",
    "    override = False\n",
    "    c_images = np.load(image_save_name)\n",
    "    df = pd.read_csv(df_save_name)\n",
    "    end = int(round(time()*1000))\n",
    "    pro_time = (end-start)/1000\n",
    "    print()\n",
    "    print(\"Got!\")\n",
    "    print(\"That took %s minutes\" % (pro_time / 60))\n",
    "    return df, c_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d46423fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim, regress=False, verbose=True):\n",
    "    if (verbose): print(\"Creating MLP Classifier for attributes...\")\n",
    "    # define our MLP network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "    # return our model\n",
    "    if (verbose): print(\"Created!\")\n",
    "    return model\n",
    "\n",
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False, verbose=True):\n",
    "    if (verbose): print(\"Creating CNN for images...\")\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (width, height, depth)\n",
    "    chanDim = -1\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # if this is the first CONV layer then set the input\n",
    "        # appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "        # CONV => RELU => BN => POOL\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(4)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "    # construct the CNN\n",
    "    model = Model(inputs, x)\n",
    "    # return the CNN\n",
    "    if (verbose): print(\"Created!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "164f2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_array(x, new_size):\n",
    "    new_size = (new_size[0]/x.shape[0],new_size[1]/x.shape[1], 1)\n",
    "    y = scipy.ndimage.zoom(x, new_size)\n",
    "    return y\n",
    "\n",
    "def score(model, testNumX, testImagesX, testY, verbose=False):\n",
    "    score = 0\n",
    "    start = int(round(time()*1000))\n",
    "    pred = model.predict([testNumX, testImagesX])\n",
    "    end = int(round(time()*1000))\n",
    "    for i in range(len(pred)):\n",
    "        prediction = np.where(pred[i] == np.amax(pred[i]))[0][0]\n",
    "        real = np.where(testY[i] == 1)[0][0]\n",
    "        # print(pred[i], testY[i])\n",
    "        if verbose: print(\"Predicted Class vs. Actual Class: %s %s\" % (prediction, real))\n",
    "        if (prediction == real):\n",
    "            score+=1\n",
    "        else: \n",
    "            if verbose: print(\"   Incorrect!\")\n",
    "    return score / len(pred), end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4305ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "\n",
    "def view_image():\n",
    "    import numpy as np # linear algebra\n",
    "    import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "    import skimage, os\n",
    "    from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "    from skimage.measure import label,regionprops, perimeter\n",
    "    from skimage.morphology import binary_dilation, binary_opening\n",
    "    from skimage.filters import roberts, sobel\n",
    "    from skimage import measure, feature\n",
    "    from skimage.segmentation import clear_border\n",
    "    from skimage import data\n",
    "    from scipy import ndimage as ndi\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    import scipy.misc\n",
    "    import numpy as np\n",
    "    from glob import glob\n",
    "    from skimage.io import imread\n",
    "    BASE_IMG_PATH = \"/Users/sidharthanantha/Documents/SciFair 2022/ADNI/002_S_6030/Axial_T2_STAR/2017-06-15_13_30_22.0/S573170/ADNI_002_S_6030_MR_Axial_T2_STAR__br_raw_20170616113815278_41_S573170_I861966.nii\"\n",
    "\n",
    "    image = glob(os.path.join(BASE_IMG_PATH, '*'))\n",
    "    image = glob(BASE_IMG_PATH)[0]\n",
    "    print(image)\n",
    "    %matplotlib inline\n",
    "    try:\n",
    "        import nibabel as nib\n",
    "    except:\n",
    "        raise ImportError('bip bop')\n",
    "\n",
    "    image_data = nib.load(image).get_data()\n",
    "    image_data = np.rot90(image_data)\n",
    "    # image_data = np.reshape(image_data, (44, 256, 256, 1))\n",
    "    # image_data = np.rot90(image_data) # make it axial\n",
    "    # print(image_data.shape)\n",
    "    le_img = image_data[image_data.shape[0]//2]\n",
    "    plt.imshow(le_img)\n",
    "    # print(le_img[len(le_img)//2])\n",
    "    # print(le_img.shape)\n",
    "    le_img = scale_array(le_img, (70,70))\n",
    "    plt.imshow(le_img)\n",
    "    # print(image_data[2])\n",
    "\n",
    "    \n",
    "def show_q_images(c_images, q_images):\n",
    "    n_samples = 4\n",
    "    n_channels = 4\n",
    "    fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n",
    "    for k in range(n_samples):\n",
    "        axes[0, 0].set_ylabel(\"Input\")\n",
    "        if k != 0:\n",
    "            axes[0, k].yaxis.set_visible(False)\n",
    "        axes[0, k].imshow(c_images[k, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "        # Plot all output channels\n",
    "        for c in range(n_channels):\n",
    "            axes[c + 1, 0].set_ylabel(\"Output [ch. {}]\".format(c))\n",
    "            if k != 0:\n",
    "                axes[c, k].yaxis.set_visible(False)\n",
    "            axes[c + 1, k].imshow(q_images[k, :, :, c], cmap=\"gray\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc75b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 1\n",
    "\n",
    "EPOCHS = 200\n",
    "LR = 1e-3\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ffd3c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'V3_Testing_imgweit2' # used for saving model name\n",
    "DATA_VERSION = 'V3' # used for retrieving imgs + csv, and saving imgs + df\n",
    "\n",
    "SAVE_PATH = \"/Users/sidharthanantha/Documents/SciFair 2022/SaveData\" # path for saving imgs, models, df\n",
    "IMAGE_DIR = \"/Users/sidharthanantha/Documents/SciFair 2022/Alzheimers_Dataset_%s\" % (DATA_VERSION)\n",
    "CSV_DIR = \"/Users/sidharthanantha/Documents/SciFair 2022/classical_v2_attr_data.csv\"\n",
    "\n",
    "IMG_SHAPE = (70, 70)\n",
    "MODEL_NAME = \"classifying_alzheimers_%s.model\" % VERSION # saves ml model under this name\n",
    "Y_ATTR = \"Research Group\"\n",
    "\n",
    "INCLUDE_DATA_NUMBERS = ['Weight','APOE A1','APOE A2','Age','MMSE Total Score','GDSCALE Total Score','Global CDR','FAQ Total Score','NPI-Q Total Score']\n",
    "INCLUDE_DATA_CATEGORIES = ['Sex', 'Description','Type','Imaging Protocol','Structure']\n",
    "\n",
    "\n",
    "RG_CLASSIFICATIONS = {\n",
    "    \"CN\": 0,\n",
    "    \"AD\": 1,\n",
    "    \"MCI\": 2,\n",
    "    \"EMCI\": 2,\n",
    "    \"LMCI\": 2,\n",
    "    \"SMC\": 2,\n",
    "}\n",
    "NUM_SLICES = 3 # how many brain slices\n",
    "NUM_TIMES_TEST = 5 # how many times should the alg be tested\n",
    "NUM_CLASSES = len(list(set(RG_CLASSIFICATIONS.values())))\n",
    "\n",
    "DATA_SAVE_FILENAME = \"%s_%sslices_%sclasses_%smodel\" % (DATA_VERSION, NUM_SLICES, NUM_CLASSES, VERSION) # to save dfs and imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f4de52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_COLS = [\n",
    "#     \"Boogie\",\n",
    "#     \"MMSE Total Score\", # Boogie is there to mean \"dont remove any columns\" because Boogie is not a column\n",
    "#     \"Weight\",\n",
    "#     'NPI-Q Total Score', \n",
    "#     'Sex', \n",
    "] # Each array element represents which column you want to test\n",
    "  # adding an array element will remove that column from the array and test it\n",
    "\n",
    "INCLUDE_DATA_ROWS = [\n",
    "#     ['Boogie', 'Woogie'],\n",
    "#     ['Imaging Protocol', 'Field Strength=1.5'],\n",
    "#     ['Imaging Protocol', 'Field Strength=3.0'],\n",
    "#     ['Imaging Protocol', 'Weighting=PD'],\n",
    "#     ['Imaging Protocol', 'Weighting=T1'],\n",
    "    ['Imaging Protocol', 'Weighting=T2'],\n",
    "]\n",
    "# Each array element represents the col and value you want to test\n",
    "# Adding an array element will filter the df so only that value will be in the column\n",
    "# The elements are in the format [column, value]\n",
    "\n",
    "# After running all of the Kernels, once you change these arrays, run kernels 12 and 14 again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef22066c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting Images and Data...\n",
      "\n",
      "Getting Images...\n",
      "Got!\n",
      "There are 11855 images\n",
      "\n",
      "Processing Images...\n",
      "Processed!\n",
      "DF's Shape: (1136, 22)\n",
      "\n",
      "Classical Images preprocessing...\n",
      "Saving images to /Users/sidharthanantha/Documents/SciFair 2022/SaveData/c_images_V3_3slices_3classes_V3_Testing_imgweit2model.npy\n",
      "Saving dataframe to /Users/sidharthanantha/Documents/SciFair 2022/SaveData/data_V3_3slices_3classes_V3_Testing_imgweit2model.csv\n",
      "Preprocessed!\n",
      "\n",
      "Got!\n",
      "That took 10.98015 minutes\n",
      "Shape of the Image array: (1136, 70, 210, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df, c_images = get_classical_images()\n",
    "print(\"Shape of the Image array: %s\\n\" % str(np.shape(c_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6efb433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Research Group</th>\n",
       "      <th>APOE A1</th>\n",
       "      <th>APOE A2</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Study Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Global CDR</th>\n",
       "      <th>...</th>\n",
       "      <th>GDSCALE Total Score</th>\n",
       "      <th>FAQ Total Score</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Imaging Protocol</th>\n",
       "      <th>Image ID</th>\n",
       "      <th>Structure</th>\n",
       "      <th>Registration</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>M</td>\n",
       "      <td>73.8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ADNI1/GO Month 24</td>\n",
       "      <td>7/23/2008</td>\n",
       "      <td>87.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial PD/T2 FSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...</td>\n",
       "      <td>114208</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>2220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>F</td>\n",
       "      <td>57.7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI1/GO Month 24</td>\n",
       "      <td>7/31/2008</td>\n",
       "      <td>78.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Double_TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=51.0;Manufacturer...</td>\n",
       "      <td>115004</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>3683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>F</td>\n",
       "      <td>58.7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI1/GO Month 36</td>\n",
       "      <td>4/30/2009</td>\n",
       "      <td>79.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Double_TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=48.0;Manufacturer...</td>\n",
       "      <td>142970</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002_S_0559</td>\n",
       "      <td>M</td>\n",
       "      <td>90.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ADNI1/GO Month 24</td>\n",
       "      <td>8/15/2008</td>\n",
       "      <td>81.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial PD/T2 FSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...</td>\n",
       "      <td>116573</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>6034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002_S_0559</td>\n",
       "      <td>M</td>\n",
       "      <td>91.6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ADNI1/GO Month 36</td>\n",
       "      <td>6/30/2009</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Double_TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...</td>\n",
       "      <td>147117</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>6035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>153_S_4621</td>\n",
       "      <td>M</td>\n",
       "      <td>73.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI2 Month 6-New Pt</td>\n",
       "      <td>10/30/2012</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>ASL PERFUSION</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=4.0;Matrix Z=105.0;Acquisition...</td>\n",
       "      <td>343150</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>2982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>M</td>\n",
       "      <td>77.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI1/GO Month 36</td>\n",
       "      <td>3/14/2010</td>\n",
       "      <td>80.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>AXIAL PD-T2 TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...</td>\n",
       "      <td>167947</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>941_S_1203</td>\n",
       "      <td>M</td>\n",
       "      <td>76.2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI1/GO Month 36</td>\n",
       "      <td>3/27/2010</td>\n",
       "      <td>86.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>AXIAL PD-T2 TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...</td>\n",
       "      <td>171272</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>941_S_4100</td>\n",
       "      <td>F</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI2 Month 6-New Pt</td>\n",
       "      <td>5/30/2012</td>\n",
       "      <td>79.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial T2-FLAIR</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=5.0;Matrix Z=35.0;Acquisition ...</td>\n",
       "      <td>307171</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>941_S_4292</td>\n",
       "      <td>M</td>\n",
       "      <td>77.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI2 Month 6-New Pt</td>\n",
       "      <td>6/20/2012</td>\n",
       "      <td>71.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial T2-FLAIR</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=5.0;Matrix Z=35.0;Acquisition ...</td>\n",
       "      <td>311603</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>11836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1222 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subject ID Sex  Weight  Research Group  APOE A1  APOE A2  \\\n",
       "0     002_S_0295   M    73.8               0      3.0      4.0   \n",
       "1     002_S_0413   F    57.7               0      3.0      3.0   \n",
       "2     002_S_0413   F    58.7               0      3.0      3.0   \n",
       "3     002_S_0559   M    90.9               0      3.0      4.0   \n",
       "4     002_S_0559   M    91.6               0      3.0      4.0   \n",
       "...          ...  ..     ...             ...      ...      ...   \n",
       "1217  153_S_4621   M    73.6               2      3.0      3.0   \n",
       "1218  941_S_1202   M    77.1               0      3.0      3.0   \n",
       "1219  941_S_1203   M    76.2               0      3.0      3.0   \n",
       "1220  941_S_4100   F    69.9               0      3.0      3.0   \n",
       "1221  941_S_4292   M    77.1               0      3.0      3.0   \n",
       "\n",
       "                     Visit  Study Date   Age  Global CDR  ...  \\\n",
       "0        ADNI1/GO Month 24   7/23/2008  87.2         0.0  ...   \n",
       "1        ADNI1/GO Month 24   7/31/2008  78.6         0.0  ...   \n",
       "2        ADNI1/GO Month 36   4/30/2009  79.4         0.0  ...   \n",
       "3        ADNI1/GO Month 24   8/15/2008  81.6         0.0  ...   \n",
       "4        ADNI1/GO Month 36   6/30/2009  82.5         0.0  ...   \n",
       "...                    ...         ...   ...         ...  ...   \n",
       "1217  ADNI2 Month 6-New Pt  10/30/2012  70.5         0.5  ...   \n",
       "1218     ADNI1/GO Month 36   3/14/2010  80.7         0.5  ...   \n",
       "1219     ADNI1/GO Month 36   3/27/2010  86.6         0.5  ...   \n",
       "1220  ADNI2 Month 6-New Pt   5/30/2012  79.5         0.0  ...   \n",
       "1221  ADNI2 Month 6-New Pt   6/20/2012  71.7         0.0  ...   \n",
       "\n",
       "      GDSCALE Total Score  FAQ Total Score  Modality      Description  \\\n",
       "0                     0.0              0.0       MRI  Axial PD/T2 FSE   \n",
       "1                     0.0              0.0       MRI       Double_TSE   \n",
       "2                     0.0              0.0       MRI       Double_TSE   \n",
       "3                     5.0              0.0       MRI  Axial PD/T2 FSE   \n",
       "4                     0.0              0.0       MRI       Double_TSE   \n",
       "...                   ...              ...       ...              ...   \n",
       "1217                  3.0              0.0       MRI    ASL PERFUSION   \n",
       "1218                  0.0             10.0       MRI  AXIAL PD-T2 TSE   \n",
       "1219                  0.0              2.0       MRI  AXIAL PD-T2 TSE   \n",
       "1220                  1.0              0.0       MRI   Axial T2-FLAIR   \n",
       "1221                  0.0              0.0       MRI   Axial T2-FLAIR   \n",
       "\n",
       "          Type                                   Imaging Protocol Image ID  \\\n",
       "0     Original  Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...   114208   \n",
       "1     Original  Slice Thickness=3.0;Matrix Z=51.0;Manufacturer...   115004   \n",
       "2     Original  Slice Thickness=3.0;Matrix Z=48.0;Manufacturer...   142970   \n",
       "3     Original  Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...   116573   \n",
       "4     Original  Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...   147117   \n",
       "...        ...                                                ...      ...   \n",
       "1217  Original  Slice Thickness=4.0;Matrix Z=105.0;Acquisition...   343150   \n",
       "1218  Original  Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...   167947   \n",
       "1219  Original  Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...   171272   \n",
       "1220  Original  Slice Thickness=5.0;Matrix Z=35.0;Acquisition ...   307171   \n",
       "1221  Original  Slice Thickness=5.0;Matrix Z=35.0;Acquisition ...   311603   \n",
       "\n",
       "     Structure  Registration Downloaded  \n",
       "0        Brain        native       2220  \n",
       "1        Brain        native       3683  \n",
       "2        Brain        native       3682  \n",
       "3        Brain        native       6034  \n",
       "4        Brain        native       6035  \n",
       "...        ...           ...        ...  \n",
       "1217     Brain        native       2982  \n",
       "1218     Brain        native       9237  \n",
       "1219     Brain        native      10002  \n",
       "1220     Brain        native       2857  \n",
       "1221     Brain        native      11836  \n",
       "\n",
       "[1222 rows x 22 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f1fff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splite(split, verbose=True):\n",
    "    (trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
    "\n",
    "    trainY = to_categorical(np.array(trainAttrX[Y_ATTR]))\n",
    "    testY = to_categorical(np.array(testAttrX[Y_ATTR]))\n",
    "    trainAttrX\n",
    "\n",
    "    trainNumXs, all_data_info = test_process_lattributes(df, trainAttrX)\n",
    "    testNumXs, all_data_info = test_process_lattributes(df, testAttrX)\n",
    "    all_dat = []\n",
    "    \n",
    "    for i in range(len(testNumXs)):\n",
    "        all_dat.append([\n",
    "            trainNumXs[i], testNumXs[i], trainImagesX, testImagesX, trainY, testY\n",
    "        ])\n",
    "    \n",
    "    return all_dat, all_data_info\n",
    "\n",
    "def make(trainNumX, testNumX, trainImagesX, testImagesX, trainY, testY, verbose=True):\n",
    "    mlp = create_mlp(trainNumX.shape[1], regress=False, verbose=verbose)\n",
    "    cnn = create_cnn(*np.shape(trainImagesX[0]), regress=False, verbose=verbose)\n",
    "    combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "    x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "    x = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "    opt = Adam(learning_rate=1e-3, decay=1e-3 / 200)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt)\n",
    "    return model\n",
    "\n",
    "def traine(trainNumX, testNumX, trainImagesX, testImagesX, trainY, testY, model, verbose=True):\n",
    "    if (verbose): print(\"Fitting...\")\n",
    "    start = int(round(time()*1000))\n",
    "    model.fit(\n",
    "        x=[trainNumX, trainImagesX], y=trainY,\n",
    "        epochs=EPOCHS, batch_size=8, verbose=False)\n",
    "    end = int(round(time()*1000))\n",
    "    train_time = (end-start)/1000\n",
    "    if (verbose): print(\"Fitted!\")\n",
    "    return model, train_time\n",
    "\n",
    "def teste(trainNumX, testNumX, trainImagesX, testImagesX, trainY, testY, train_time, model):\n",
    "    lescore, pred_time = score(model, testNumX, testImagesX, testY, verbose=False)\n",
    "\n",
    "    print(\"After training the model with %s inputs and %s tests, here are the results\"%(trainY.shape[0], testY.shape[0]))\n",
    "    print(\"-----------\")\n",
    "    print(\"Time to train (%s inputs, epoch=%s): %s mins - (%s sec)\" % (trainY.shape[0], EPOCHS, round(train_time/60, 2), round(train_time, 2)))\n",
    "    print(\"Time to predict (%s values) in ms: %s\" % (testY.shape[0], pred_time))\n",
    "    print(\"Score: %s%%\" % (lescore*100))\n",
    "    print(\"-----------\")\n",
    "    \n",
    "    model.save(SAVE_PATH + \"/\" + MODEL_NAME)\n",
    "    return lescore*100\n",
    "\n",
    "def do(split, which):\n",
    "    print(\"--------%s--------\" % which)\n",
    "    print()\n",
    "    total_total = []\n",
    "    all_all_the_data, all_data_info = splite(split, verbose=False)\n",
    "    for index, all_the_data in enumerate(all_all_the_data):\n",
    "        print(\"%s----------\" % all_data_info[index])\n",
    "        total_scores = 0\n",
    "        total_time = 0\n",
    "        for i in range(NUM_TIMES_TEST):\n",
    "            model = make(*all_the_data, verbose=False)\n",
    "            model, train_time = traine(*all_the_data, model)\n",
    "            the_score = teste(*all_the_data, train_time, model)\n",
    "            total_scores += the_score\n",
    "            total_time += train_time\n",
    "        print(\"\\n\")\n",
    "        stats = [(total_scores/NUM_TIMES_TEST), (total_time/NUM_TIMES_TEST), all_data_info[index]]\n",
    "        total_total.append(stats)\n",
    "        print()\n",
    "        print(\"%s----------\" % stats[2])\n",
    "\n",
    "        print(\"Avg Scores:     %s%%\" % round(stats[0], 5))\n",
    "        print(\"Avg Train Time: %s mins - (%s sec)\" % (round(stats[1]/60, 2), round(stats[1], 2)))\n",
    "    return total_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a66ec98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Classical--------\n",
      "\n",
      "Processing Scan Attributes...\n",
      "Processed!\n",
      "Processing Scan Attributes...\n",
      "Processed!\n",
      "Filter from Imaging Protocol: Weighting=T2----------\n",
      "Fitting...\n",
      "Fitted!\n",
      "After training the model with 852 inputs and 284 tests, here are the results\n",
      "-----------\n",
      "Time to train (852 inputs, epoch=200): 56.34 mins - (3380.27 sec)\n",
      "Time to predict (284 values) in ms: 5706\n",
      "Score: 77.46478873239437%\n",
      "-----------\n",
      "Fitting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f3/048ydxg12gv9kdbdkq4drhkc0000gn/T/ipykernel_52582/3184120875.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mavgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mavgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#     avgs.append(avg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m print(\"Using DataVersion %s, Model %s, Img Shape %s, %s slice(s), %s classifications:\" \n",
      "\u001b[0;32m/var/folders/f3/048ydxg12gv9kdbdkq4drhkc0000gn/T/ipykernel_52582/3713184864.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(split, which)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_TIMES_TEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mall_the_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mall_the_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mthe_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mall_the_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mtotal_scores\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mthe_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f3/048ydxg12gv9kdbdkq4drhkc0000gn/T/ipykernel_52582/3713184864.py\u001b[0m in \u001b[0;36mtraine\u001b[0;34m(trainNumX, testNumX, trainImagesX, testImagesX, trainY, testY, model, verbose)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainNumX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainImagesX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         epochs=EPOCHS, batch_size=8, verbose=False)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m     return fit_loop(\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4184\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4186\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   4187\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   4188\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1481\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1484\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# split_q = train_test_split(df, q_images, test_size=0.25, random_state=42)\n",
    "split_c = train_test_split(df, c_images, test_size=0.25, random_state=42)\n",
    "splits = [\n",
    "#     [split_q, \"Quantum\"],\n",
    "    [split_c, \"Classical\"]\n",
    "]\n",
    "avgs = []\n",
    "for er in splits:\n",
    "    avgs = do(*er)\n",
    "#     avgs.append(avg)\n",
    "print(\"Using DataVersion %s, Model %s, Img Shape %s, %s slice(s), %s classifications:\" \n",
    "      % (DATA_VERSION, VERSION, IMG_SHAPE, NUM_SLICES, NUM_CLASSES))\n",
    "for avg in avgs:\n",
    "    print()\n",
    "    print(\"%s----------\" % avg[2])\n",
    "    \n",
    "    print(\"Avg Scores:     %s%%\" % round(avg[0], 5))\n",
    "    print(\"Avg Train Time: %s mins - (%s sec)\" % (round(avg[1]/60, 2), round(avg[1], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b5c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c46d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

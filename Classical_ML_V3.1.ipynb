{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c086b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vikram & Sahana\n",
    "# Jan 17 2022\n",
    "# Classical Machine Learning Model V3\n",
    "# Detecting Severity of Alzheimer's with brain scans more accurately\n",
    "\n",
    "# Differences from V2\n",
    "#   Including more congitive impairments\n",
    "#   Including 3 slices at the Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434bfd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tflearn\n",
    "import nibabel as nib\n",
    "nib.imageglobals.logger.level = 40\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_utils import to_categorical, image_preloader\n",
    "from tflearn.metrics import Accuracy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage, os\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78dc1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images():\n",
    "    print(\"Processing Images...\")\n",
    "    df = pd.read_csv(CSV_DIR) # reads in csv file\n",
    "    df[\"Downloaded\"] = \"\" # creates new Downloaded column\n",
    "    \n",
    "    \n",
    "    for index, row in df.iterrows(): # goes through every row\n",
    "        \n",
    "        # CONNECTING EACH IMAGE TO ROW IN THE \n",
    "        id = row['Image ID']\n",
    "        for i in range(len(images_set)): # checks through all the images\n",
    "            if \"I%s\" % id in image_info[i][0]:\n",
    "                # if the image id is in the file name of the image being checked\n",
    "                df.at[index,'Downloaded'] = i # store the index\n",
    "                image_info[i][1] = True\n",
    "        \n",
    "        # CHANGING RESEARCH GROUP TO A NUMBER\n",
    "        #if (row['Research Group'] == \"AD\"): df.at[index,'Research Group'] = 1\n",
    "        #elif (row['Research Group'] == \"CN\"): df.at[index,'Research Group'] = 0\n",
    "        #else: \n",
    "        #    df.at[index,'Research Group'] = 2\n",
    "            \n",
    "        if (row['Research Group'] in RG_CLASSIFICATIONS.keys()): \n",
    "            df.at[index,'Research Group'] = RG_CLASSIFICATIONS[row['Research Group']]\n",
    "        else:\n",
    "            df.at[index,'Research Group'] = -1\n",
    "        # CHANGING ANY COL,ROW WHERE IT SAYS NAN\n",
    "        for col in df:\n",
    "            if index > 0 and pd.isnull(row[col]):\n",
    "                if row[\"Subject ID\"] == df.at[index-1,\"Subject ID\"]:\n",
    "                    df.at[index, col] = df.at[index-1,col]\n",
    "        \n",
    "#         if row['Subject ID'] == df.at[index-1,\"Subject ID\"] and row['Research Group'] != df.at[index-1,\"Research Group\"]:\n",
    "#             print(index, )\n",
    "        \n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)   \n",
    "    df.dropna(inplace=True) \n",
    "    \n",
    "    \n",
    "    df2 = df.loc[df['Downloaded'] != \"\"]\n",
    "    df3 = df2.loc[df2['Research Group'] != -1]\n",
    "    print(\"Processed!\")\n",
    "    return df3\n",
    "\n",
    "def process_lattributes(df, dat):\n",
    "    print(\"Processing Scan Attributes...\")\n",
    "    cs = MinMaxScaler()\n",
    "    continuous = cs.fit_transform(dat[INCLUDE_DATA_NUMBERS])\n",
    "    categoricals = []\n",
    "    for i in INCLUDE_DATA_CATEGORIES:\n",
    "        zipBinarizer = LabelBinarizer().fit(df[i])\n",
    "        categorical = zipBinarizer.transform(dat[i])\n",
    "        categoricals.append(categorical)\n",
    "    \n",
    "    x = np.hstack([continuous, *categoricals])\n",
    "    print(\"Processed!\")\n",
    "    return x\n",
    "\n",
    "def get_data():\n",
    "    print(\"Getting Image Data...\")\n",
    "    path = IMAGE_DIR\n",
    "    images = []\n",
    "    image_info = []\n",
    "    for fol1 in tqdm(os.listdir(path), disable=True):\n",
    "        if fol1 == \".DS_Store\": continue\n",
    "        path1 = os.path.join(path, fol1)\n",
    "        for fol2 in tqdm(os.listdir(path1), disable=True):\n",
    "            if fol2 == \".DS_Store\": continue\n",
    "            path2 = os.path.join(path1, fol2)\n",
    "            for fol3 in tqdm(os.listdir(path2), disable=True):\n",
    "                if fol3 == \".DS_Store\": continue\n",
    "                path3 = os.path.join(path2, fol3)\n",
    "                for fol4 in tqdm(os.listdir(path3), disable=True):\n",
    "                    if fol4 == \".DS_Store\": continue\n",
    "                    path4 = os.path.join(path3, fol4)\n",
    "                    # After going through all of the subfolders, we can finally see the image\n",
    "                    for img in tqdm(os.listdir(path4), disable=True):\n",
    "                        if img == \".DS_Store\": continue\n",
    "                        # print(img)\n",
    "                        try:\n",
    "                            path5 = os.path.join(path4, img)\n",
    "                            image_data = nib.load(path5).get_fdata() # get the numbers of the 3D image\n",
    "                            image_data = np.rot90(image_data) # make it axial\n",
    "                            \"\"\"\n",
    "                            our_slice = image_data[image_data.shape[0]//2] # get the very middle slice\n",
    "                            our_slice_reshaped = scale_array(our_slice, IMG_SHAPE)\n",
    "                            images.append(our_slice_reshaped)\n",
    "                            plt.imshow(our_slice_reshaped)\n",
    "                            \"\"\"\n",
    "                            \n",
    "                            big_image = np.empty([IMG_SHAPE[0], IMG_SHAPE[1]*NUM_IMAGES, 1])\n",
    "                            for i in range(NUM_IMAGES):\n",
    "                                our_slice = image_data[image_data.shape[0]*(i+1)//(NUM_IMAGES+1)]\n",
    "                                our_slice_reshaped = scale_array(our_slice, IMG_SHAPE)\n",
    "                                for r in range(IMG_SHAPE[0]): \n",
    "                                    for c in range(IMG_SHAPE[1]): \n",
    "                                        this_number = our_slice_reshaped[r,c,0]\n",
    "                                        big_image[r,c+(IMG_SHAPE[1]*i),0] = this_number\n",
    "\n",
    "                            # print(big_image.shape)\n",
    "                            # plt.imshow(big_image)\n",
    "                            images.append(big_image) # add it to the list\n",
    "                            \n",
    "                            \n",
    "                            image_info.append([img, False])\n",
    "                        except:\n",
    "                            pass\n",
    "    print(\"Got!\")\n",
    "    return images, image_info\n",
    "\n",
    "def scale_array(x, new_size):\n",
    "    new_size = (new_size[0]/x.shape[0],new_size[1]/x.shape[1], 1)\n",
    "    y = scipy.ndimage.zoom(x, new_size)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46423fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim, regress=False, verbose=True):\n",
    "    if (verbose): print(\"Creating MLP Classifier for attributes...\")\n",
    "    # define our MLP network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "    # return our model\n",
    "    if (verbose): print(\"Created!\")\n",
    "    return model\n",
    "\n",
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False, verbose=True):\n",
    "    if (verbose): print(\"Creating CNN for images...\")\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (width, height, depth)\n",
    "    chanDim = -1\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # if this is the first CONV layer then set the input\n",
    "        # appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "        # CONV => RELU => BN => POOL\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(4)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "    # construct the CNN\n",
    "    model = Model(inputs, x)\n",
    "    # return the CNN\n",
    "    if (verbose): print(\"Created!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164f2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model,verbose=False):\n",
    "    score = 0\n",
    "    start = int(round(time()*1000))\n",
    "    pred = model.predict([testNumX, testImagesX])\n",
    "    end = int(round(time()*1000))\n",
    "    for i in range(len(pred)):\n",
    "        prediction = np.where(pred[i] == np.amax(pred[i]))[0][0]\n",
    "        real = np.where(testY[i] == 1)[0][0]\n",
    "        # print(pred[i], testY[i])\n",
    "        if verbose: print(\"Predicted Class vs. Actual Class: %s %s\" % (prediction, real))\n",
    "        if (prediction == real):\n",
    "            score+=1\n",
    "        else: \n",
    "            if verbose: print(\"   Incorrect!\")\n",
    "    return score / len(pred), end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "\n",
    "def view_image():\n",
    "    import numpy as np # linear algebra\n",
    "    import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "    import skimage, os\n",
    "    from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "    from skimage.measure import label,regionprops, perimeter\n",
    "    from skimage.morphology import binary_dilation, binary_opening\n",
    "    from skimage.filters import roberts, sobel\n",
    "    from skimage import measure, feature\n",
    "    from skimage.segmentation import clear_border\n",
    "    from skimage import data\n",
    "    from scipy import ndimage as ndi\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    import scipy.misc\n",
    "    import numpy as np\n",
    "    from glob import glob\n",
    "    from skimage.io import imread\n",
    "    BASE_IMG_PATH = \"/Users/sidharthanantha/Documents/SciFair 2022/ADNI/002_S_6030/Axial_T2_STAR/2017-06-15_13_30_22.0/S573170/ADNI_002_S_6030_MR_Axial_T2_STAR__br_raw_20170616113815278_41_S573170_I861966.nii\"\n",
    "\n",
    "    image = glob(os.path.join(BASE_IMG_PATH, '*'))\n",
    "    image = glob(BASE_IMG_PATH)[0]\n",
    "    print(image)\n",
    "    %matplotlib inline\n",
    "    try:\n",
    "        import nibabel as nib\n",
    "    except:\n",
    "        raise ImportError('bip bop')\n",
    "\n",
    "    image_data = nib.load(image).get_data()\n",
    "    image_data = np.rot90(image_data)\n",
    "    # image_data = np.reshape(image_data, (44, 256, 256, 1))\n",
    "    # image_data = np.rot90(image_data) # make it axial\n",
    "    # print(image_data.shape)\n",
    "    le_img = image_data[image_data.shape[0]//2]\n",
    "    plt.imshow(le_img)\n",
    "    # print(le_img[len(le_img)//2])\n",
    "    # print(le_img.shape)\n",
    "    le_img = scale_array(le_img, (70,70))\n",
    "    plt.imshow(le_img)\n",
    "    # print(image_data[2])\n",
    "    # It's a little smushed but that's ok\n",
    "view_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffd3c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"/Users/sidharthanantha/Documents/SciFair 2022/Alzheimers_Dataset_V3\"\n",
    "CSV_DIR = \"/Users/sidharthanantha/Documents/SciFair 2022/classical_v2_attr_data.csv\"\n",
    "IMG_SHAPE = (70, 70)\n",
    "LR = 1e-3\n",
    "MODEL_NAME = \"classifying_alzheimers_v3.model\"\n",
    "Y_ATTR = \"Research Group\"\n",
    "INCLUDE_DATA_NUMBERS = ['Weight','APOE A1','APOE A2','Age','MMSE Total Score','GDSCALE Total Score','Global CDR','FAQ Total Score','NPI-Q Total Score']\n",
    "INCLUDE_DATA_CATEGORIES = ['Sex', 'Description','Type','Imaging Protocol','Structure']\n",
    "EPOCHS = 200\n",
    "NUM_IMAGES = 3\n",
    "RG_CLASSIFICATIONS = {\n",
    "    \"CN\": 0,\n",
    "    \"AD\": 1,\n",
    "    \"MCI\": 2,\n",
    "    \"EMCI\": 2,\n",
    "    \"LMCI\": 2,\n",
    "    \"SMC\": 2,\n",
    "}\n",
    "NUM_CLASSES = len(list(set(RG_CLASSIFICATIONS.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c4a8b9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Image Data...\n",
      "Got!\n",
      "There are 11855 images\n"
     ]
    }
   ],
   "source": [
    "images_set, image_info = get_data()\n",
    "print(\"There are %s images\" % len(images_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bfaafdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Images...\n",
      "Processed!\n",
      "DF's Shape: (2324, 22)\n"
     ]
    }
   ],
   "source": [
    "df = process_images()\n",
    "print(\"DF's Shape: %s\" % str(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f6efb433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Research Group</th>\n",
       "      <th>APOE A1</th>\n",
       "      <th>APOE A2</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Study Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Global CDR</th>\n",
       "      <th>...</th>\n",
       "      <th>GDSCALE Total Score</th>\n",
       "      <th>FAQ Total Score</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Imaging Protocol</th>\n",
       "      <th>Image ID</th>\n",
       "      <th>Structure</th>\n",
       "      <th>Registration</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>M</td>\n",
       "      <td>72.6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ADNI1/GO Month 12</td>\n",
       "      <td>5/25/2007</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>3-plane localizer</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=5.0;Matrix Z=5.0;Acquisition T...</td>\n",
       "      <td>55271</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>M</td>\n",
       "      <td>72.6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ADNI1/GO Month 12</td>\n",
       "      <td>5/25/2007</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial PD/T2 FSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=51.0;Acquisition ...</td>\n",
       "      <td>55277</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>2221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>M</td>\n",
       "      <td>73.8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ADNI1/GO Month 24</td>\n",
       "      <td>7/23/2008</td>\n",
       "      <td>87.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial PD/T2 FSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...</td>\n",
       "      <td>114208</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>2220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>F</td>\n",
       "      <td>60.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI Baseline</td>\n",
       "      <td>5/19/2006</td>\n",
       "      <td>76.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Double_TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=52.0;Manufacturer...</td>\n",
       "      <td>15804</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>10459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>F</td>\n",
       "      <td>60.8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI1/GO Month 6</td>\n",
       "      <td>11/15/2006</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial PD/T2 FSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=52.0;Acquisition ...</td>\n",
       "      <td>29707</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50388</th>\n",
       "      <td>941_S_4377</td>\n",
       "      <td>F</td>\n",
       "      <td>123.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ADNI2 Month 6-New Pt</td>\n",
       "      <td>8/16/2012</td>\n",
       "      <td>70.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>localizer</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=8.0;Matrix Z=1.0;Acquisition T...</td>\n",
       "      <td>324374</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>10328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50389</th>\n",
       "      <td>941_S_4377</td>\n",
       "      <td>F</td>\n",
       "      <td>123.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ADNI2 Month 6-New Pt</td>\n",
       "      <td>8/16/2012</td>\n",
       "      <td>70.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>localizer</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=8.0;Matrix Z=1.0;Acquisition T...</td>\n",
       "      <td>324372</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>10329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50393</th>\n",
       "      <td>941_S_4377</td>\n",
       "      <td>F</td>\n",
       "      <td>123.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ADNI2 Month 6-New Pt</td>\n",
       "      <td>8/16/2012</td>\n",
       "      <td>70.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>AXIAL_T2_STAR</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=4.0;Matrix Z=44.0;Acquisition ...</td>\n",
       "      <td>324377</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>10327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50420</th>\n",
       "      <td>941_S_4420</td>\n",
       "      <td>M</td>\n",
       "      <td>75.3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI2 Month 6-New Pt</td>\n",
       "      <td>12/21/2012</td>\n",
       "      <td>82.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>ADNI_gre_field_mapping</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=45.0;Acquisition ...</td>\n",
       "      <td>352803</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50426</th>\n",
       "      <td>941_S_4420</td>\n",
       "      <td>M</td>\n",
       "      <td>75.3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ADNI2 Month 6-New Pt</td>\n",
       "      <td>12/21/2012</td>\n",
       "      <td>82.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MRI</td>\n",
       "      <td>ADNI_gre_field_mapping</td>\n",
       "      <td>Original</td>\n",
       "      <td>Slice Thickness=3.0;Matrix Z=45.0;Acquisition ...</td>\n",
       "      <td>352820</td>\n",
       "      <td>Brain</td>\n",
       "      <td>native</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3297 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subject ID Sex  Weight  Research Group  APOE A1  APOE A2  \\\n",
       "9      002_S_0295   M    72.6               0      3.0      4.0   \n",
       "11     002_S_0295   M    72.6               0      3.0      4.0   \n",
       "13     002_S_0295   M    73.8               0      3.0      4.0   \n",
       "34     002_S_0413   F    60.4               0      3.0      3.0   \n",
       "38     002_S_0413   F    60.8               0      3.0      3.0   \n",
       "...           ...  ..     ...             ...      ...      ...   \n",
       "50388  941_S_4377   F   123.4               4      3.0      4.0   \n",
       "50389  941_S_4377   F   123.4               4      3.0      4.0   \n",
       "50393  941_S_4377   F   123.4               4      3.0      4.0   \n",
       "50420  941_S_4420   M    75.3               3      3.0      3.0   \n",
       "50426  941_S_4420   M    75.3               3      3.0      3.0   \n",
       "\n",
       "                      Visit  Study Date   Age  Global CDR  ...  \\\n",
       "9         ADNI1/GO Month 12   5/25/2007  86.0         0.0  ...   \n",
       "11        ADNI1/GO Month 12   5/25/2007  86.0         0.0  ...   \n",
       "13        ADNI1/GO Month 24   7/23/2008  87.2         0.0  ...   \n",
       "34            ADNI Baseline   5/19/2006  76.4         0.0  ...   \n",
       "38         ADNI1/GO Month 6  11/15/2006  76.9         0.0  ...   \n",
       "...                     ...         ...   ...         ...  ...   \n",
       "50388  ADNI2 Month 6-New Pt   8/16/2012  70.1         0.5  ...   \n",
       "50389  ADNI2 Month 6-New Pt   8/16/2012  70.1         0.5  ...   \n",
       "50393  ADNI2 Month 6-New Pt   8/16/2012  70.1         0.5  ...   \n",
       "50420  ADNI2 Month 6-New Pt  12/21/2012  82.2         0.5  ...   \n",
       "50426  ADNI2 Month 6-New Pt  12/21/2012  82.2         0.5  ...   \n",
       "\n",
       "       GDSCALE Total Score  FAQ Total Score  Modality             Description  \\\n",
       "9                      0.0              0.0       MRI       3-plane localizer   \n",
       "11                     0.0              0.0       MRI         Axial PD/T2 FSE   \n",
       "13                     0.0              0.0       MRI         Axial PD/T2 FSE   \n",
       "34                     0.0              0.0       MRI              Double_TSE   \n",
       "38                     0.0              0.0       MRI         Axial PD/T2 FSE   \n",
       "...                    ...              ...       ...                     ...   \n",
       "50388                  2.0              2.0       MRI               localizer   \n",
       "50389                  2.0              2.0       MRI               localizer   \n",
       "50393                  2.0              2.0       MRI           AXIAL_T2_STAR   \n",
       "50420                  4.0              1.0       MRI  ADNI_gre_field_mapping   \n",
       "50426                  4.0              1.0       MRI  ADNI_gre_field_mapping   \n",
       "\n",
       "           Type                                   Imaging Protocol Image ID  \\\n",
       "9      Original  Slice Thickness=5.0;Matrix Z=5.0;Acquisition T...    55271   \n",
       "11     Original  Slice Thickness=3.0;Matrix Z=51.0;Acquisition ...    55277   \n",
       "13     Original  Slice Thickness=3.0;Matrix Z=48.0;Acquisition ...   114208   \n",
       "34     Original  Slice Thickness=3.0;Matrix Z=52.0;Manufacturer...    15804   \n",
       "38     Original  Slice Thickness=3.0;Matrix Z=52.0;Acquisition ...    29707   \n",
       "...         ...                                                ...      ...   \n",
       "50388  Original  Slice Thickness=8.0;Matrix Z=1.0;Acquisition T...   324374   \n",
       "50389  Original  Slice Thickness=8.0;Matrix Z=1.0;Acquisition T...   324372   \n",
       "50393  Original  Slice Thickness=4.0;Matrix Z=44.0;Acquisition ...   324377   \n",
       "50420  Original  Slice Thickness=3.0;Matrix Z=45.0;Acquisition ...   352803   \n",
       "50426  Original  Slice Thickness=3.0;Matrix Z=45.0;Acquisition ...   352820   \n",
       "\n",
       "      Structure  Registration Downloaded  \n",
       "9         Brain        native       2222  \n",
       "11        Brain        native       2221  \n",
       "13        Brain        native       2220  \n",
       "34        Brain        native      10459  \n",
       "38        Brain        native        153  \n",
       "...         ...           ...        ...  \n",
       "50388     Brain        native      10328  \n",
       "50389     Brain        native      10329  \n",
       "50393     Brain        native      10327  \n",
       "50420     Brain        native        363  \n",
       "50426     Brain        native        362  \n",
       "\n",
       "[3297 rows x 22 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7069c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Image array: (2324, 70, 70, 1)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "for index in list(df[\"Downloaded\"]):\n",
    "    images.append(images_set[index])\n",
    "images = np.array(images)\n",
    "print(\"Shape of the Image array: %s\" % str(np.shape(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a66ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Scan Attributes...\n",
      "Processed!\n",
      "Processing Scan Attributes...\n",
      "Processed!\n"
     ]
    }
   ],
   "source": [
    "split = train_test_split(df, images, test_size=0.25, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
    "\n",
    "trainY = to_categorical(np.array(trainAttrX[Y_ATTR]))\n",
    "testY = to_categorical(np.array(testAttrX[Y_ATTR]))\n",
    "trainAttrX\n",
    "\n",
    "trainNumX = process_lattributes(df, trainAttrX)\n",
    "testNumX = process_lattributes(df, testAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f1fff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(verbose=True):\n",
    "    mlp = create_mlp(trainNumX.shape[1], regress=False, verbose=verbose)\n",
    "    cnn = create_cnn(*np.shape(trainImagesX[0]), regress=False, verbose=verbose)\n",
    "    combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "    x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "    x = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "    opt = Adam(learning_rate=1e-3, decay=1e-3 / 200)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt)\n",
    "    return model\n",
    "\n",
    "def train(model, verbose=True):\n",
    "    if (verbose): print(\"Fitting...\")\n",
    "    start = int(round(time()*1000))\n",
    "    model.fit(\n",
    "        x=[trainNumX, trainImagesX], y=trainY,\n",
    "        epochs=EPOCHS, batch_size=8, verbose=False)\n",
    "    end = int(round(time()*1000))\n",
    "    train_time = (end-start)/1000\n",
    "    if (verbose): print(\"Fitted!\")\n",
    "    return model, train_time\n",
    "\n",
    "def test(model):\n",
    "    lescore, pred_time = score(model, verbose=False)\n",
    "\n",
    "    print(\"After training the model with %s inputs and %s tests, here are the results\"%(trainY.shape[0], testY.shape[0]))\n",
    "    print(\"-----------\")\n",
    "    print(\"Time to train (%s inputs, epoch=%s): %s sec (%s mins)\" % (trainY.shape[0], EPOCHS, train_time, train_time/60))\n",
    "    print(\"Time to predict (%s values) in ms: %s\" % (testY.shape[0], pred_time))\n",
    "    print(\"Score: %s%%\" % (lescore*100))\n",
    "\n",
    "    model.save(MODEL_NAME)\n",
    "    return lescore*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f58076c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MLP Classifier for attributes...\n",
      "Created!\n",
      "Creating CNN for images...\n",
      "Created!\n",
      "Fitting...\n",
      "Fitted!\n",
      "After training the model with 1743 inputs and 581 tests, here are the results\n",
      "-----------\n",
      "Time to train (1743 inputs, epoch=200): 4590.473 sec (76.50788333333334 mins)\n",
      "Time to predict (581 values) in ms: 1387\n",
      "Score: 97.24612736660929%\n",
      "\n",
      "\n",
      "Avg Scores: 97.24612736660929\n"
     ]
    }
   ],
   "source": [
    "NUM_TIMES_TEST = 1\n",
    "\n",
    "total_scores = 0\n",
    "for i in range(NUM_TIMES_TEST):\n",
    "    model = make()\n",
    "    model, train_time = train(model)\n",
    "    the_score = test(model)\n",
    "    total_scores += the_score\n",
    "    \n",
    "print(\"\\n\\nAvg Scores: %s\" % (total_scores/NUM_TIMES_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a74df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf865309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
